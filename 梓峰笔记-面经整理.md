[toc]

# 各厂薪资

## 知乎整理

https://zhuanlan.zhihu.com/p/137320301



# 2021年金三银四面试时间表

| 面试企业     | 一面                                | 二面                              | 三面 | HR面 |
| ------------ | ----------------------------------- | --------------------------------- | ---- | ---- |
| 欢聚集团     | 3月23日上午10点到场，基础需加强，凉 |                                   |      |      |
| 某z电商***   | 3月25日上午10点到场，对答如流，成   | 3月25日上午11点到场，对答如流，成 | 无   | 待定 |
| 某a游戏***   | 3月27日上午10点到场                 |                                   |      |      |
| 某s物流***   | 3月30日上午10点到场                 |                                   |      |      |
| 某z短视频*** | 4月1日下午14点视频                  |                                   |      |      |



# 高级Java工程师面试总结



##3月23日上午10点到场1面

自我介绍

1. java线程构造方法有哪几个
2. threadlocal讲一下
3. 固定线程池缺点
4. 线程池拒绝策略（抛异常Abort、自己干CallerRun、遗弃自我Discard、遗弃最老DiscardOldest）
5. array queue 和 linked queue区别，队列增删操作区别（队头出，队尾进，纯数据结构）
6. java锁有哪几种？（共享\排他、悲观\乐观、公平\非公平、可重入\不可重入、自旋锁\适应性自旋锁、无锁\偏向锁\轻量级锁\重量级锁）
7. ReentrantLock和 synchronized的区别（都是可重入锁，前者锁粒度更细，因有条件锁，后者锁优化更细，因有锁升级）
8. jvm内存区域有哪些
9. 创建一个对象是放在栈还是堆（逃逸分析，没逃则栈否则堆）
10. gc算法有哪些
11. 如何回收对象，可达性分析的缺点（对象互相依赖）
12. **jvm调优方法有哪些（答得不好，没说出好几个）**
13. 数据库有哪些引擎
14. myisam 和 innodb有什么区别（非聚簇索引 vs 聚簇索引）
15. **大数据量场景下，哪个引擎读性能更好（居然是myisam好，我惊呆了，原因是什么）**
16. 事务隔离级别有哪些（读未提交、读提交RC、可重复读RR、序列化）
17. RC 和 RR有什么区别（gap-lock、next-key-lock，范围锁）
18. mysql默认事务隔离级别（可重复读RR）
19. mysql如何解决幻读（RR范围锁）
20. redis了解么，平时用来做什么
21. redis数据结构有哪些
22. redis在秒杀下怎么用（setnx+incr加锁，防超卖）
23. **redis如何做动态排名，命令是哪个（答得不好，连zrange都说不出来）**
24. 消息队列了解么，平时用来做什么（削峰填谷、系统解耦、异步调用）
25. **rabbitmq的交换机有哪些（没复习到，露馅了）**
26. 消息队列防止丢消息，消息积压如何处理，消息如何处理重复消费。
27. **rabbitmq拿监控数据的api是哪个（故意刁难了，将军了）**
28. **kafka了解么？（故意问你简历上没有的，将军plus）**

你有什么问题想问的



面试小结：

总的来说，由于有两年没出去面试了，加上卡时间点到场面试，导致心情紧张，面试过程多半处于被动，往往出现脑筋急转弯。前面都答得很顺利，但总感觉没达到面试官想要的结果，也许回答得不完整，或者答题结构和思路比较混乱；自己感觉在redis和rabbitmq的部分回答得不满意，自己连redis做动态排序的命令zrange都忘了，而rabbitmq，交换机exchanger有几个都不知道，虽然用分布式队列的一般常见问题勉强转移视线，但面试官最后还是用rabbitmq的监控API来将我一军。面试官初步评价是基础需要加强。面试结束的时候，总觉得面试官很赶时间，匆忙把我送到电梯，那种场景感觉像在赶客，导致我回家后失落的心情迟迟不能平复，没办法，自己菜不能怨别人，后面还有几家重要的面试安排，相信会比这次面试的难题更高，唯有努力复习才能成功上岸，冲冲冲。



## 3月25日上午10点到场1面2面

自我介绍

1. 介绍项目，用到了什么技术，遇到了什么问题，如何解决
2. 栈溢出是什么，如何导致栈溢出，如何排查栈溢出，结合实际谈谈原因是什么（深层树递归遍历，Thread stackSize过小）
3. 堆溢出是什么，如何导致堆溢出，如何排查堆溢出，结合实际谈谈原因是什么（内存泄漏导致内存溢出，ThreadLocal内存泄漏）
4. 元空间溢出是什么，如何导致元空间溢出，如何排查元空间溢出，结合实际谈谈原因是什么（class文件太多，MetaspaceMaxSize太小，动态类加载）
5. 动态类加载用在什么地方（jdbc数据源，JDK动态代理）
6. 为什么JDK动态代理需要用到类加载（因为Proxy.newInstance时候需要传递ClassLoader对象）
7. 频繁Full GC问题如何排查（看GC日志，看日志中的各年代分区回收情况）
8. rabbitmq在项目中怎么用的，如果生产者不做限流，消费者如何处理限流？（消息积压+Direct.Exchange+时间轮RoutingKey）
9. 如何处理MySQL慢查询，如何排查，如何解决？
10. 如何优化MySQL查询性能，数据层面、查询层面分别谈谈
11. Java如何发生死锁，如何排查死锁，如何解决死锁问题？
12. RC 和 RR有什么区别，RC解决了什么问题，RR解决了什么问题，RC有什么问题，RR有什么问题 ？
13. redis在秒杀下怎么用，redis分布式锁有什么问题？
14. 如何设计API（我回答RESTful、HTTP协议细节，说我答太细，让我说限流、熔断、故障转移）
15. UML会么，序列图中的方框代表什么，同步异步调用分别用什么线，状态图了解么？（瞬间回到大三交课程作业那时）
16. 大学本科学什么专业，学了哪些课程？（瞬间回到大四打印成绩表那时）
17. 对加班有什么看法？（求生欲捉急）
18. 对高级Java工程师有什么看法，你心目中高级Java工程师应该是怎么样的。（灵魂拷问，说我年资太轻，没8年没达到高级要求）
19. 图遍历找最短路径，如何存储图？（狄氏遍历，节点关系表+节点表）



面试小结：

一面和二面都很顺利，虽然做不到谈笑风生，但至少对答如流，没有卡壳的现象。面试官都是从简历上写的项目进行深入问，当然我在简历上也写了可以让他们可以提问的点，例如做过JVM内存调优、死锁排查、SQL慢查询、MySQL性能调优、大促秒杀防超卖场景的项目。二面的面试官在临近面试结束的时候问了几个让我有点觉得尬聊的问题：UML、本科课程、加班看法、高级Java工程师看法。二面最后突然问了个基础题：图遍历找最短路径+图的数据结构，感觉是放大招，但我说了狄氏遍历和节点关系表。然后他就没问啥了。隐隐觉得他有点歧视我的年龄，嫌我太年轻，没说我项目经验少，只是单纯地认为我不够8年工作经验，即便技术面过了还是不满足高级Java工程师的要求，emmm，他看起来像80后。





# 面经整理

参考文献：https://github.com/Flamewaker/DailySummary/blob/master/%E9%9D%A2%E7%BB%8F%E6%95%B4%E7%90%86.md

参考文献：https://github.com/Snailclimb/JavaGuide



# 复习整理



## Linux

### Linux五种IO模型

#### 阻塞IO模型

```mermaid
sequenceDiagram
    autonumber
    participant A as application
    participant K as kernel
    
    A ->> A: recvfrom
    A ->> K: system call
    Note left of A: process blocks in call to recvfrom
    K ->> K: no datagram ready
    Note right of K: wait for data
    K ->> K: datagram ready
    K ->> K: copy datagram
    Note right of K: copy data from kernal to user
    K ->> K: copy complete
    K ->> A: return OK
    A ->> A: process datagram
```

This mode is very simple. The system calls **recvfrom** After the function, the thread waits until:
The first step is to load the file into kernel mode, and the second step is to load the file into user mode.



#### 非阻塞IO模型

```mermaid
sequenceDiagram
    autonumber
    participant A as application
    participant K as kernel
    
    loop polling
      A ->> A: recvfrom
      A ->> K: system call
      Note left of A: process repeatedly calls recvfrom, 
      Note left of A: waiting for an OK return (polling)
      K ->> K: no datagram ready
      Note right of K: wait for data
      K ->> A: EWOULDBLOCK
    end
    A ->> A: recvfrom
    A ->> K: system call
    K ->> K: datagram ready
    K ->> K: copy datagram
    Note right of K: copy data from kernal to user
    K ->> K: copy complete
    K ->> A: return OK
    A ->> A: process datagram
```

The system keeps passing **recvfrom** Poll until the first step is completed, and then block the data from kernel state to user state in the second step. 

The non blocking IO mode here mainly refers to the first step, loading data to the kernel state. This process is non blocking, and polling is used to determine whether the data is ready in the kernel.



#### IO复用模型

```mermaid
sequenceDiagram
    autonumber
    participant A as application
    participant K as kernel
    
    A ->> A: select
    Note left of A: process blocks in call to select,
    Note left of A: waiting for one of possibly many sockets to become readable
    A ->> K: system call
    K ->> K: no datagram ready
    Note right of K: wait for data
    K ->> K: datagram ready
    K ->> A: return readable
    A ->> A: recvfrom
    Note left of A: process blocks while data copied into application buffer
    A ->> K: system call
    K ->> K: copy datagram
    Note right of K: copy data from kernel to user
    K ->> K: copy complete
    K ->> A: return OK
    A ->> A: process datagram
```



The system first checks whether the kernel data is ready through select.

When the kernel data is loaded, the system calls **recvfrom** to load kernel state data into user state.

It looks like the first and second steps are blocking operations, but select can handle multiple file handles (including sockets) at the same time at a very low cost.



#### 信号驱动IO模型

```mermaid
sequenceDiagram
    autonumber
    participant A as application
    participant K as kernel
    
    A ->> A: establish SIGIO
    A ->> K: sigaction system call
    K ->> A: return
    Note left of A: process continues executing
    Note right of K: wait for data
    K ->> K: datagram ready
    K ->> A: deliver SIGIO
    A ->> A: signal handler
    A ->> A: recvfrom
    Note left of A: process blocks while data copied into application buffer
    A ->> K: system call
    K ->> K: copy datagram
    Note right of K: copy data from kernel to user
    K ->> K: copy complete
    K ->> A: return OK
    A ->> A: process datagram
    
```

The first step is to register a callback function and notify me when the kernel data is ready.

At this time, the system can do other things without blocking waiting for kernel data.

Step 2, blocking call **recvfrom**, load the kernel’s data into the user state.



#### 异步IO模型

```mermaid
sequenceDiagram
    autonumber
    participant A as application
    participant K as kernel
    
    A ->> A: aio_read
    A ->> K: system call
    K ->> K: no datagram ready
    K ->> A: return
    Note left of A: process continues executing
    Note right of K: wait for data
    K ->> K: datagram ready
    K ->> K: copy datagram
    Note right of K: copy data from kernel to user
    K ->> K: copy complete
    K ->> A: deliver signal that specified in aio_read
    A ->> A: signal handler
    A ->> A: process datagram
    
    
```

In theory, this model is a real asynchronous model, because in the above four models, in the second step: data loading from kernel state to user state is synchronous operation.

In this model, when the system loads the file, it only needs to pass AIO_ Read registers a callback to notify the current system when the file is loaded in kernel state or user state.

In this process, the system can perform other operation tasks without waiting.



#### Summary

The first four IO models [blocking IO, non blocking IO, IO multiplexing, signal driven IO] are all synchronous IO, only the last one is truly asynchronous [asynchronous IO]

**Introduction to system call**

1. The old version of NiO in java used select mode, but later changed to epoll. Why?

Because select is a polling mode, it constantly checks the status of the file handle.
Epoll is a callback mode. When the file handle is ready, it can directly callback, which is more efficient.

2. Does java have a real AIO mode?

Under Windows system, it is realized by IOCP.
In Linux system, no, because the underlying AIO layer of Linux system is still epoll.
(I guess that’s why netty uses NiO instead of AIO)

**outside the box**

In the form of dialogue, it is easy to understand
Ramble: how to explain to girlfriend what are the five IO models of Linux?

The kernel state and user state of data are also mentioned in this article. At the same time, efficient data transmission methods are introduced:
**zero-copy**, No copy operation between user state and kernel state



## Java基础



### GC算法

参考文献：https://www.jianshu.com/p/43c1b262d36b



### lock 和 synchronized的区别

参考文献：https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/multi-thread/2020%E6%9C%80%E6%96%B0Java%E5%B9%B6%E5%8F%91%E8%BF%9B%E9%98%B6%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93.md



### java默认线程池的优缺点

参考文献：https://blog.csdn.net/dakaniu/article/details/80778801



```java
public class ThreadPoolExecutor {
    public ThreadPoolExecutor(int corePoolSize,                        // 核心线程数，即便闲置也需保留，除非允许超时
                              int maximumPoolSize,                     // 最大线程数，线程池最大并发容量
                              long keepAliveTime,                      // 大于核心线程数那部分的线程的存活时间
                              TimeUnit unit,                           // keepAliveTime的时间单位
                              BlockingQueue<Runnable> workQueue,       // hold住待执行任务的工作队列
                              ThreadFactory threadFactory,             // 生产线程对象的线程工厂
                              RejectedExecutionHandler handler) {      // 拒绝执行任务的句柄，拒绝策略实现了几个句柄
      ...
    }

}
public class Executors {
  
    public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
    }
  
    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }

    public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
  
    public static ExecutorService newWorkStealingPool() {
        return new ForkJoinPool
            (Runtime.getRuntime().availableProcessors(),
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }

    public static ScheduledExecutorService newSingleThreadScheduledExecutor() {
        return new DelegatedScheduledExecutorService
            (new ScheduledThreadPoolExecutor(1));
    }

    public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
        return new ScheduledThreadPoolExecutor(corePoolSize);
    }

}
```





### Threadlocal讲一下

参考文献：https://droidyue.com/blog/2016/03/13/learning-threadlocal-in-java/



* 定义：ThreadLocal是一个关于创建线程局部变量的类。
* 原理：Thread对象有ThreadLocalMap对象，以开放式地址实现哈希表，表项为弱引用ThreadLocal类的继承类Entry，弱引用在每次gc回收周期中都会被清除，而被弱引用的对象会被标记为finalizable。
* 应用举例：统计线程池中每条线程的run次数

弱引用注释：

```java
/**
 * Weak reference objects, which do not prevent their referents from being
 * made finalizable, finalized, and then reclaimed.  Weak references are most
 * often used to implement canonicalizing mappings.
 *
 * <p> Suppose that the garbage collector determines at a certain point in time
 * that an object is <a href="package-summary.html#reachability">weakly
 * reachable</a>.  At that time it will atomically clear all weak references to
 * that object and all weak references to any other weakly-reachable objects
 * from which that object is reachable through a chain of strong and soft
 * references.  At the same time it will declare all of the formerly
 * weakly-reachable objects to be finalizable.  At the same time or at some
 * later time it will enqueue those newly-cleared weak references that are
 * registered with reference queues.
 *
 * @author   Mark Reinhold
 * @since    1.2
 */

public class WeakReference<T> extends Reference<T> {
  ...
}
```





### java线程构造方法有哪几个？

讲哪几个没用，重点在new Thread() 调用的 init() 的参数名。

```java
    /**
     * Initializes a Thread.
     *
     * @param g 线程组对象
     * @param target 实现run()方法的Runnable对象
     * @param name 线程名称
     * @param stackSize 线程栈大小，指定为0则该参被忽略
     * @param acc 访问控制上下文对象，若为空则用AccessController.getContext()
     * @param inheritThreadLocals 是否继承父线程对象的ThreadLocalMap对象
     */
    private void init(ThreadGroup g, Runnable target, String name,
                      long stackSize, AccessControlContext acc,
                      boolean inheritThreadLocals) {
      ...
    }
```



其中，线程组、线程名称、Runnable对象、stackSize都是Thread构造方法的形参。



### String、StringBuilder和StringBuffer的区别？

1. 线程安全的区别

   * String是线程安全的
     * String 的 char[] 是 final 的，是常量

   * StringBuilder不是线程安全的
     * StringBuilder的 char[] 不是 final 的，是变量

   * StringBuffer继承了StringBuilder，但StringBuffer是线程安全的
     * StringBuffer每个方法都是syncronized关键字修饰

2. 字符串长度是否可变的区别
   * String长度是不可变的
     * String 的 char[] 是 final 的，是常量
   * StringBuffer和StringBuilder长度是可以改变的
     * StringBuilder 和 StringBuffer 的 char[] 不是 final 的
     * StringBuilder扩容方法ensureCapacityInternal()，核心调用了Arrays.copy()



### 创建对象的方式有哪几种?

1. new Object();
2. Object.clone();       // native 方法，需要Cloneable接口
3. Some.class.getConstructor(Class<?>...clazz).newInstance();      // 反射机制
4. ObjectInputStream.readObject();      // Java反序列化，需要Serializable接口实现readObject()方法



### 赋值、深拷贝和浅拷贝的区别？

这三者的区别如下，不过比较的前提都是**针对引用类型**：

- 当我们把一个对象赋值给一个新的变量时，**赋的其实是该对象的在栈中的地址，而不是堆中的数据**。也就是两个对象指向的是同一个存储空间，无论哪个对象发生改变，其实都是改变的存储空间的内容，因此，两个对象是联动的。
- 浅拷贝：重新在堆中创建内存，拷贝前后对象的基本数据类型互不影响，但拷贝前后对象的引用类型因共享同一块内存，会相互影响。
- 深拷贝：从堆内存中开辟一个新的区域存放新对象，对对象中的子对象进行递归拷贝,拷贝前后的两个对象互不影响。

举例：

1. 引用赋值：String str = "hello";
2. 值赋值：int i = 1;
3. 浅拷贝：Object.clone();
4. 深拷贝：JSONObject.fromJSON(String json);



### 内存泄露和内存溢出的区别？

内存泄漏：指无用对象（不再使用的对象）持续占有内存或无用对象的内存得不到及时释放，从而造成内存空间的浪费称为内存泄漏

内存溢出：指程序运行过程中无法申请到足够的内存而导致的一种错误。内存溢出通常发生于OLD段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况

两者关系：如果内存泄漏的错误一直不处理，在有限内存空间的条件下，最终一定会出现内存溢出的错误，抛出OutOfMemoryError异常



### 强引用，弱引用，软引用，虚引用的区别？

参考文献：https://www.cnblogs.com/CodeBear/p/12447554.html



1. 强引用：被强引用关联的对象不会被回收，使用 new 一个新对象的方式来创建强引用

   ```java
   Object obj = new Object();   // 创建
   obj = null;                  // 取消关联以便回收
   System.gc();                 // 手动gc可回收
   ```

2. 软引用：被软引用关联的对象只有在内存不够的情况下才会被回收，使用 SoftReference 类来创建软引用

   ```java
   SoftReference<Object> objSoftReference = new SoftReference<>(new Object());    // 创建
   Object obj = objSoftReference.get();             // 获取
   System.gc();                                     // 内存不够的情况下才会被回收，手动gc不可回收
   ```

3. 弱引用：被弱引用关联的对象一定会被回收，即它只能存活到下一次垃圾回收发生之前，使用 WeakReference 类来创建弱引用

   ```java
   WeakReference<Object> weakReference = new WeakReference<>(new Object());       // 创建
   Object obj = weakReference.get();                // 获取
   System.gc();                                     // 手动gc可回收
   // ThreadLocal、WeakHashMap 有用到弱引用
   ```

4. 虚引用：一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象；虚引用必须与ReferenceQueue一起使用，当GC准备回收一个对象，如果发现它还有虚引用，就会在回收之前，把这个虚引用加入到与之关联的ReferenceQueue中。

   ```java
   ReferenceQueue queue = new ReferenceQueue();
   List<byte[]> bytes = new ArrayList<>();
   PhantomReference<Object> reference = new PhantomReference<Student>(new Object(),queue);
   Object obj = reference.get();        // obj == null，无法通过虚引用获取真实地址的对象
   new Thread(() -> {
       for (int i = 0; i < 100;i++ ) {
           bytes.add(new byte[1024 * 1024]);    // 逐渐增加内存直到发生gc
       }
   }).start();
   
   new Thread(() -> {
       while (true) {
           Reference poll = queue.poll();       // 发生gc时，虚引用对象被回收，并把回收通知塞到引用队列
           if (poll != null) {
               System.out.println("虚引用被回收了：" + poll);    // 发生gc时，打印这句话
           }
       }
   }).start();
   ```

   

### Java BIO、NIO和AIO的区别？

参考文献：https://developer.aliyun.com/article/726698



**同步和异步**

同步：指的是用户进程触发 IO 操作并等待或者轮询的去查看 IO 操作是否就绪。

异步：异步是指用户进程触发IO操作以后便开始做自己的事情，而当 IO 操作已经完成的时候会得到 IO 完成的通知，它的特点就是通知。

区别：IO 操作主要分为两个步骤，即发起 IO 请求和实际 IO 操作，同步与异步的区别就在于第二个步骤是否阻塞。若实际 IO 操作阻塞请求进程，即请求进程需要等待或者轮询查看 IO 操作是否就绪，则为同步 IO；若实际 IO 操作并不阻塞请求进程，而是由操作系统来进行实际 IO 操作并将结果返回，则为异步 IO。

观察角度：计算机把内存分为用户内存和系统内存两部分，同步和异步是针对应用程序(用户内存)和内核(系统内存)的交互而言的。



**阻塞和非阻塞**

阻塞：所谓阻塞方式就是指，当视图对文件描述符或者网络套接字进行读写时，如果当时没有东西可读，或者暂时不可写，程序就进入等待状态，直到有东西读或者写。

非阻塞：所谓的非阻塞方式就是指，当视图对文件描述符或者网络套接字进行读写时，如果没有东西可读，或者不可写，读写函数马上返回，无须等待。

区别：IO 操作主要分为两个步骤，即发起 IO 请求和实际 IO 操作，阻塞与非阻塞的区别就在于第一个步骤是否阻塞。若发起 IO 请求后请求线程一直等待实际 IO 操作完成，则为阻塞 IO；若发起 IO 请求后请求线程返回而不会一直等待，即为非阻塞 IO。

观察角度：阻塞和非阻塞是针对于进程在访问数据的时候，根据 IO 操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。



**BIO 编程模型**

采用 BIO 通信模型的服务端，通常有一个独立的 Acceptor 线程负责监听客户端的连接，它接收到客户端的连接请求之后，为每个客户端创建一个新的线程进行链路处理，处理完之后，通过输出流返回应答客户端，线程销毁。这就是典型的`一请求一应答`通信模型。这个是在多线程情况下执行的。当在单线程环境条件下时，在 while 循环中服务端会调用 accept 方法等待接收客户端的连接请求，一旦收到这个连接请求，就可以建立 socket，并在 socket 上进行读写操作，此时不能再接收其他客户端的连接请求，只能等待同当前服务端连接的客户端的操作完成或者连接断开。

该模型最大的问题就是缺乏弹性伸缩能力，当客户端并发访问量增加后，服务端的线程个数和客户端并发访问数呈 1:1 的正比关系，由于线程是 Java 虚拟机非常宝贵的系统资源，当线程数膨胀之后，系统的性能将急剧下降，随着并发访问量的继续增大，系统会发生线程堆栈溢出、创建新线程失败等问题，并最终导致进程宕机或者僵死，不能对外提供服务。



**伪异步 I/O 编程**

为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化，后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M：线程池最大线程数N的比例关系，其中M可以远远大于N，通过线程池可以灵活的调配线程资源。设置线程的最大值，防止由于海量并发接入导致线程耗尽。
采用线程池和任务队列可以实现一种叫做伪异步的I/O通信框架。

当有新的客户端接入时，将客户端的 Socket 封装成一个 Task(该任务实现 Java.lang.Runnablle 接口)投递到后端的线程池中进行处理，JDK 的线程池维护一个消息队列和N个活跃线程对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。

由于线程池和消息队列都是有界的，因此，无论客户端并发连接数多大，它都不会导致线程个数过于膨胀或者内存溢出，相对于传统的一连接一线程模型，是一种改良。

伪异步I/O通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。但是由于它底层的通信依然采用同步阻塞模型，因此无法从根本上解决问题。

通过对输入和输出流的 API 文档进行分析，我们了解到读和写操作都是同步阻塞的，阻塞的时间取决于对方 IO 线程的处理速度和网络 IO 的传输速度，本质上讲，我们无法保证生产环境的网络状况和对端的应用程序能足够快，如果我们的应用程序依赖对方的处理速度，它的可靠性就会非常差。



**NIO编程模型**

与 Socket 类和 ServerSocket 类对应，NIO 也提供了 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现，在 JDK1.4 中引入。这两种新增的通道都支持阻塞和非阻塞两种模式。阻塞模式非常简单，但性能和可靠性都不好，非阻塞模式正好相反。我们可以根据自己的需求来选择合适的模式，一般来说，低负载、低并发的应用程序可以选择同步阻塞 IO 以降低编程复杂度，但是对于高负载、高并发的网络应用，需要使用 NIO 的非阻塞模式进行开发。

- (1)缓冲区 Buffer

Buffer 是一个对象，它包含一些要写入或者要读出的数据，在 NIO 库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的；在写入数据时，写入到缓冲区中，任何时候访问 NIO 中的数据，都是通过缓冲区进行操作。
缓冲区实质上是一个数组。通常它是一个字节数组(ByteBuffer)，也可以使用其他种类的数组，但是一个缓冲区不仅仅是一个数组，缓冲区提供了对数据的结构化访问以及维护读写位置(limit)等信息。常用的有ByteBuffer，其它还有CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。

- (2)通道 Channel

Channel 是一个通道，可以通过它读取和写入数据，它就像自来水管一样，网络数据通过 Channel 读取和写入。通道与流的不同之处在于通道是双向的，流只是一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)，而且通道可以用于读、写或者用于读写。同时Channel 是全双工的，因此它可以比流更好的映射底层操作系统的API。特别是在Unix网络编程中，底层操作系统的通道都是全双工的，同时支持读写操作。我们常用到的 ServerSocketChannnel 和 SocketChannel 都是SelectableChannel 的子类。

- (3)多路复用器Selector

多路复用器 Selector 是 Java NIO 编程的基础，多路复用器提供选择已经就绪的任务的能力，简单的说，Selector 会不断的轮询注册在其上的 Channel，如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I/O 操作。

一个多用复用器 Selector 可以同时轮询多个 Channel，由于 JDK 使用了 epoll() 代替传统的 select() 实现，所以它并没有最大连接句柄 1024/2048 的限制，这也意味着只需要一个线程负责 Selector 的轮询，就可以接入成千上万的客户端。

尽管 NIO 编程难度确实比同步阻塞 BIO 大很多，但是我们要考虑到它的优点：

(1)客户端发起的连接操作是异步的，可以通过在多路复用器注册 OP_CONNECT 等后续结果，不需要像之前的客户端那样被同步阻塞。

(2)SocketChannel 的读写操作都是异步的，如果没有可读写的数据它不会同步等待，直接返回，这样IO通信线程就可以处理其它的链路，不需要同步等待这个链路可用。

(3)线程模型的优化：由于 JDK 的 Selector 在 Linux 等主流操作系统上通过 epoll 实现，它没有连接句柄数的限制(只受限于操作系统的最大句柄数或者对单个进程的句柄限制)，这意味着一个 Selector 线程可以同时处理成千上万个客户端连接，而且性能不会随着客户端的增加而线性下降，因此，它非常适合做高性能、高负载的网络服务器。



**AIO编程模型**

JDK1.7 升级了 NIO 类库，升级后的 NIO 类库被称为NIO2.0。也就是我们要介绍的 AIO。NIO2.0 引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。异步通道提供两种方式获取操作结果。

(1)通过 `Java.util.concurrent.Future` 类来表示异步操作的结果；

(2)在执行异步操作的时候传入一个`Java.nio.channels.CompletionHandler`接口的实现类作为操作完成的回调。

NIO2.0 的异步套接字通道是真正的异步非阻塞 IO，它对应 UNIX 网络编程中的事件驱动 IO(AIO)，它不需要通过多路复用器(Selector)对注册的通道进行轮询操作即可实现异步读写，从而简化了 NIO 的编程模型。

我们可以得出结论：异步 Socket Channel是被动执行对象，我们不需要想NIO编程那样创建一个独立的IO线程来处理读写操作。对于`AsynchronousServerSocketChannel`和`AsynchronousSocketChannel`，它们都由 JDK 底层的线程池负责回调并驱动读写操作。正因为如此，基于 NIO2.0 新的异步非阻塞 Channel 进行编程比 NIO 编程更为简单。



### 是不是所有的对象和数组都会在堆内存分配空间？

参考文献：https://mp.weixin.qq.com/s?__biz=MzAxOTQxOTc5NQ==&mid=2650500024&idx=1&sn=0997c486387bf56bbe8ca909d55a7edf&chksm=83c88c44b4bf05521d66f6a396550cd9c8379c3fdddee1ee198968f6a9ddd172550d3329a94d&scene=21#wechat_redirect



**总结**

在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。

但是，有一种特殊情况，那就是如果经过**逃逸分析**后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。

因此，局部变量实际上是在栈上分配的。

**如何进行逃逸分析？**

例如：-Xmx4G -Xms4G **-XX:-DoEscapeAnalysis** -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError

在Java代码运行时，通过JVM参数可指定是否开启逃逸分析，

* -XX:+DoEscapeAnalysis ：表示开启逃逸分析
* -XX:-DoEscapeAnalysis ： 表示关闭逃逸分析



### 双亲委派模型是什么？

参考文献：https://juejin.cn/post/6844903838927814669

参考文献：https://www.cnblogs.com/lanxuezaipiao/p/4138511.html

参考文献：https://www.cnblogs.com/xrq730/p/4847337.html



JVM预定义的三种类型类加载器：

- **启动（Bootstrap）类加载器**：是用本地代码实现的类装入器，它负责将 `<Java_Runtime_Home>/lib`下面的类库加载到内存中（比如`rt.jar`）。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作。
- **标准扩展（Extension）类加载器**：是由 Sun 的 `ExtClassLoader（sun.misc.Launcher$ExtClassLoader）`实现的。它负责将`< Java_Runtime_Home >/lib/ext`或者由系统变量 `java.ext.dir`指定位置中的类库加载到内存中。开发者可以直接使用标准扩展类加载器。
- **系统（System）类加载器**：是由 Sun 的 `AppClassLoader（sun.misc.Launcher$AppClassLoader）`实现的。它负责将系统类路径（`CLASSPATH`）中指定的类库加载到内存中。开发者可以直接使用系统类加载器。

除了以上列举的三种类加载器，还有一种比较特殊的类型，**线程上下文类加载器**。



双亲委派机制描述：
某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，**依次递归**，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。



如何打破双亲委派机制？

自己写一个自定义类加载器，在findClass()方法中不调用super.findClass()，直接自行读取某个路径的class字节码文件，最后用this.defineClass()方法获取Class类的对象并返回出去。在外部，Class.forName()可以指定自己写的自定义类加载器进行类加载。



### Java中Class.forName和ClassLoader的区别？

类的加载：

* 加载：通过类的全限定名获取二进制字节流，将二进制字节流转换成方法区中的运行时数据结构，在内存中生成Java.lang.class对象；

* 链接：执行下面的校验、准备和解析步骤，其中解析步骤是可以选择的；
  * 校验：检查导入类或接口的二进制数据的正确性；（文件格式验证，元数据验证，字节码验证，符号引用验证）
  * 准备：给类的静态变量分配内存并初始化内存空间；
  * 解析：将常量池中的符号引用转成直接引用；

* 初始化：激活类的静态变量的初始化Java代码和静态Java代码块，并初始化程序员设置的变量值。

在java中Class.forName()和ClassLoader都可以对类进行加载。ClassLoader就是遵循**双亲委派模型**最终调用启动类加载器的类加载器，实现的功能是通过一个类的全限定名来获取描述此类的二进制字节流，获取到二进制流后放到JVM中。classloader只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容。

Class.forName()方法实际上也是调用的CLassLoader来实现的。Class.forName()除了将类的.class文件加载到jvm中之外，还会对类进行初始化，执行类中的static块。

```java
@CallerSensitive
public static Class<?> forName(String className) throws ClassNotFoundException {
    Class<?> caller = Reflection.getCallerClass();
    return forName0(className, true, ClassLoader.getClassLoader(caller), caller);
}
```

最后调用的方法是forName0这个方法，在这个forName0方法中的第二个参数被默认设置为了true，这个参数代表是否对加载的类进行初始化，设置为true时会类进行初始化，代表会执行类中的静态代码块，以及对静态变量的赋值等操作。



### 单例模式代码

```java
// 线程安全，调用效率高，但是不能延时加载，单例未使用的时候便创建完成，可能造成资源浪费。
class Singleton1 {
    private static Singleton1 instance = new Singleton1();
    private Singleton1() {}
    public static Singleton1 getInstance() {
        return instance;
    }
}

// 线程安全，调用效率不高，但是能延时加载，线程安全通过synchronized实现
class Singleton2 {
    private static Singleton2 instance;
    private Singleton2() {}
    public static synchronized Singleton2 getSingleton() {
        if (instance == null) {
            instance = new Singleton2();
        }
        return instance;
    }
}

// 双重校验锁，线程安全，延迟加载。
// instance = new Singleton3(); 分为三个过程。
// 1. 为instance分配内存空间
// 2. 初始化instance
// 3. 将instance指向分配的内存空间
// 变量如果没有声明成volatile，多线程下会导致一个线程获得一个未初始化的实例。
// volatile 保证在JVM的内存模型中各个线程的内存可见性
class Singleton3 {
    private static volatile Singleton3 instance;
    private Singleton3() {}
    public static Singleton3 getSingleton() {
        if (instance == null) {
            synchronized (Singleton3.class) {
                if (instance == null) {
                    instance = new Singleton3();
                }
            }
        }
        return instance;
    }
}

// 静态内部类可以不依赖外部类的实例而被实例化。只有调用getSingleton()才进行初始化。
class Singleton4 {
    private Singleton4() {}
    private static class Inner {
        private static Singleton4 instance = new Singleton4();
    }
    public static Singleton4 getSingleton() {
        return Inner.instance;
    }

}
```



### Java的synchronized关键字的内置锁的锁升级过程

参考文献：https://blog.csdn.net/zqz_zqz/article/details/70233767



synchronized的执行过程：
1. 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁
2. 如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1
3. 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。
4. 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁
5. 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
6. 如果自旋成功则依然处于轻量级状态。
7. 如果自旋失败，则升级为重量级锁。



### Java的各种“锁”事

参考文献：https://tech.meituan.com/2018/11/15/java-lock.html



**1.乐观锁 VS 悲观锁**

先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。

而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。

乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。



**2.自旋锁 VS 适应性自旋锁**

阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。

在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。

而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。

自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。

自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。



**3.无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁**

偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。

* 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。
* 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。
* 轻量级锁是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。
* 升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。



**4.Java对象头和Monitor** 

在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的。以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。

* Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。
* Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。



Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。

Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。

synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。



锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。



### JVM调优方法

参考文献：https://juejin.cn/post/6844904127512723470

参考文献：https://my.oschina.net/u/4297759/blog/4674682



### JVM调优工具

**jps**（常用）

查看JVM进程号

```shell
root@p:~# jps
21154 email-server.jar
31554 CoreServer-1.0.0.jar
14274 canary-server.jar
4643 user-server.jar
15556 scheduler-server.jar
15110 eureka.jar
31693 CoreServer-1.0.0.jar
16624 message-server.jar
4721 Jps
17650 community-server.jar
9811 app.jar
6548 app.jar
16854 data-server.jar
10103 app.jar
3870 GradleDaemon
17087 wechat-server.jar
```



**jdb**（少用）

在线调试工具

```shell
root@p:~# jdb -help
```



**jhat**（少用）

读取 jmap -dump 的dump文件，启动web服务器默认端口7000，提供在线查询内存对象服务

```shell
root@p:~# jhat coredump.txt 
Reading from coredump.txt...
Dump file created Fri Mar 26 12:06:08 CST 2021
Snapshot read, resolving...
Resolving 3023096 objects...
Chasing references, expect 604 dots............................................................................................................
Eliminating duplicate references......................................................................................................
Snapshot resolved.
Started HTTP server on port 7000
Server is ready.
```



**jmap**（常用）

内存监控与内存使用状态导出工具

* -clstats：to connect to running process and print class loader statistics
* -finalizerinfo：to connect to running process and print information on objects awaiting finalization
* -histo：to connect to running process and print histogram of java object heap
* -dump：to connect to running process and dump java heap

```shell
root@p:~# jmap -clstats 31554
GC.class_stats command requires -XX:+UnlockDiagnosticVMOptions

root@p:~# jmap -finalizerinfo 31554
No instances waiting for finalization found

root@p:~# jmap -histo 31554 | head -10
 num     #instances         #bytes  class name
----------------------------------------------
   1:       1007494       63719856  [C
   2:        554005       53065240  [B
   3:        528531       21141240  sun.nio.cs.UTF_8$Decoder
   4:        864283       20742792  java.lang.String
   5:        487854       19514160  java.util.LinkedHashMap$Entry
   6:        372232       12426408  [Ljava.lang.Object;
   
root@p:~# jmap -dump:live,format=b,file=heapdump.txt 31554
Heap dump file created
```



**jstack**（常用）

参考文献：https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr016.html#BABFCHDE

内存线程状态监控，死锁检测

```shell
root@p:~# jstack -l -e 31554 | head -10
2021-03-26 17:54:54
Full thread dump OpenJDK 64-Bit Server VM (25.265-b01 mixed mode):

"Attach Listener" #320 daemon prio=9 os_prio=0 tid=0x00007f3388067800 nid=0x1154 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

"NFLoadBalancer-PingTimer-email-server" #313 daemon prio=5 os_prio=0 tid=0x00007f33900ca800 nid=0xe75 in Object.wait() [0x00007f336069a000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	at java.util.TimerThread.mainLoop(Timer.java:552)
```



**jstat**（常用）

参考文献：https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr017.html#BABCDBEA

GC动态监控，Full GC观察

```shell
root@p:~# jstat -options
-class
-compiler
-gc
-gccapacity
-gccause
-gcmetacapacity
-gcnew
-gcnewcapacity
-gcold
-gcoldcapacity
-gcutil
-printcompilation
```



**jcmd**（实际很常用）

能干jps、jstack、jmap

```shell
root@p:~# jcmd 25436 help
25436:
The following commands are available:
VM.native_memory
ManagementAgent.stop
ManagementAgent.start_local
ManagementAgent.start
VM.classloader_stats
GC.rotate_log
Thread.print
GC.class_stats
GC.class_histogram
GC.heap_dump
GC.finalizer_info
GC.heap_info
GC.run_finalization
GC.run
VM.uptime
VM.dynlibs
VM.flags
VM.system_properties
VM.command_line
VM.version
help
```





## 数据库

### 联合索引那些事

参考文献：https://juejin.cn/post/6844904073955639304



### SQL优化

参考文献：https://dev.mysql.com/doc/refman/8.0/en/statement-optimization.html





### 关于索引的各种轰炸。Mysql的索引，以及B+树与hash索引的区别，为什么不采用B树而采用B+树？B树和B+树的区别？

参考文献：https://github.com/Flamewaker/DailySummary/blob/master/%E9%9D%A2%E7%BB%8F%E6%95%B4%E7%90%86.md



B+树：非叶子节点不存储data，只存储索引，这样可以放更多的索引，data只存在叶子节点，这样到达叶子节点的路径查询长度都一样，使用b+树索引更加稳定。叶子节点用双向指针连接，提高区间访问的性能。B+ 树索引，底层是多路查询平衡树，节点是天然有序的（左节点小于服节点，右节点大于父节点），所以对于范围查找的时候不需要做全表扫描；

hash索引：底层是哈希表，数据存储在哈希表中顺序是没有关联的，所以他不适合范围查找，如果要范围查找就需要全表扫描，他只适合全值扫描；简单的来说就是hash索引适合等值查找，不适合范围查找。

MySQL索引使用的数据结构主要有**BTree索引** 和 **哈希索引** 。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。

MySQL的BTree索引使用的是B树中的B+Tree，但对于主要的两种存储引擎的实现方式是不同的。

* **MyISAM:** B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。

* **InnoDB:** 其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。**在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。** **因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。**



### 数据库问题，说一下从你打开命令行到发送请求，mysql服务器的整个相应流程?

MySQL 主要分为 Server 层和引擎层。

Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用, redolog 只有 InnoDB 有。

引擎层是插件式的，目前主要包括，MyISAM, InnoDB, Memory 等。

* **连接器：** 身份认证和权限相关(登录 MySQL 的时候)。

* **查询缓存：** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。

* **分析器：**没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。先词法分析，再语法分析

* **优化器：**按照 MySQL 认为最优的方案去执行。

* **执行器：**执行语句，然后从存储引擎返回数据。

**查询语句**：

```sql
select * from tb_student  A where A.age='18' and A.name=' 张三 ';
```

先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。

通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student,需要查询所有的列，查询条件是这个表的 id='1'。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。

接下来就是优化器进行确定执行方案，上面的 sql 语句，可以有两种执行方案：

1. 先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。
2. 先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。

那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。

进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。

**更新语句**：

```sql
update tb_student A set A.age='19' where A.name=' 张三 ';
```

我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。其实条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块式 **bin log（归档日志）** ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 **redo log（重做日志）**，我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：

* 先查询到张三这一条数据，如果有缓存，也是会用到缓存。

* 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。

* 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。

* 更新完成。

> **这里肯定有同学会问，为什么要用两个日志模块，用一个日志模块不行吗?**
>
> 这是因为最开始 MySQL 并没与 InnoDB 引擎( InnoDB 引擎是其他公司以插件形式插入 MySQL 的) ，MySQL 自带的引擎是 MyISAM，但是我们知道 redo log 是 InnoDB 引擎特有的，其他存储引擎都没有，这就导致会没有 crash-safe 的能力(crash-safe 的能力即使数据库发生异常重启，之前提交的记录都不会丢失)，binlog 日志只能用来归档。
>
> 并不是说只用一个日志模块不可以，只是 InnoDB 引擎就是通过 redo log 来支持事务的。那么，又会有同学问，我用两个日志模块，但是不要这么复杂行不行，为什么 redo log 要引入 prepare 预提交状态？这里我们用反证法来说明下为什么要这么做？
>
> - **先写 redo log 直接提交，然后写 binlog**，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 binlog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。
> - **先写 binlog，然后写 redo log**，假设写完了 bin log，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 bin log 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。
>
> 如果采用 redo log 两阶段提交的方式就不一样了，写完 binglog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？ 这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下：
>
> - 判断 redo log 是否完整，如果判断是完整的，就立即提交。
> - 如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。
>
> 这样就解决了数据一致性的问题。

> - 查询语句的执行流程如下：权限校验（如果命中缓存）--> 查询缓存 --> 分析器 --> 优化器 --> 权限校验 --> 执行器 --> 引擎
> - 更新语句执行流程如下：分析器 --> 权限校验 --> 执行器 --> 引擎 -- redo log(prepare 状态) --> binlog --> redo log(commit状态)





## 消息队列

### 为什么使用消息队列？

参考文献：https://xie.infoq.cn/article/84f9538c7468ed89434c68686



优点：

* 解耦：解耦调用下游系统接口及其接口适配
* 异步：下游系统发生故障不影响上游系统运行，若消费失败则可重新消费。
* 削峰：充当缓冲队列，用以适配上游系统高并发写入，通过积压消息来适配下游系统低并发写入。



缺点：

* 系统可用性低：MQ挂了，整个系统都挂了
* 系统复杂度高：MQ存在消息重复消费、消息丢失、消息消费乱序
* 一致性问题：在分布式事务场景下，部分下游系统发生故障，数据如何回滚



主流MQ：

* ActiveMQ：单机吞吐量：万级；时效性：毫秒级；可用性：高；消息可靠性：小概率丢数据；
* RabbitMQ：单机吞吐量：万级；时效性：微秒级；可用性：高；消息可靠性：基本不丢；
* RocketMQ：单机吞吐量：十万级；时效性：毫秒级；可用性：非常高；消息可靠性：可配置0丢失；
* Kafka：单机吞吐量：十万级；时效性：毫秒级；可用性：非常高；消息可靠性：可配置0丢失；



### 如何保证消息队列的高可用？

参考文献：https://xie.infoq.cn/article/b73758f12905a71b1efe1b4d2



策略1：集群，集群每个节点都具备相同的数据，节点之间互不干涉，某个节点挂了也不影响集群提供服务。

策略2：主从，主节点负责读写，从节点只负责读，主节点同步数据给从节点，主节点挂了可选举从节点代替之。



RabbitMQ：普通集群模式（多节点存元数据+单节点存队列内容）、镜像集群模式（多节点存元数据和队列内容）

RocketMQ & Kafka：Broker主从 + NameServer集群



### 如何保证消息不被重复消费？

参考文献：https://xie.infoq.cn/article/72f1f64f7bca1b55d9934666b



消息被重复消费的原因：

- 生产者：生产者可能会重复推送一条数据到 MQ 中，为什么会出现这种情况呢？也许是一个 Controller 接口被重复调用了 2 次，没有做接口幂等性导致的；也可能是推送消息到 MQ 时响应比较慢，生产者的重试机制导致再次推送了一次消息。
- MQ：在消费者消费完一条数据响应 ack 信号消费成功时，MQ 突然挂了，导致 MQ 以为消费者还未消费该条数据，MQ 恢复后再次推送了该条消息，导致了重复消费。
- 消费者：消费者已经消费完了一条消息，正准备但是还未给 MQ 发送 ack 信号时，此时消费者挂了，服务重启后 MQ 以为消费者还没有消费该消息，再次推送了该条消息。



**消费端幂等性**

消费者怎么解决重复消费问题呢？这个问题解决起来也比较简单，这里提供两种方法

- 状态判断法：消费者消费数据后把消费数据记录在 redis 中，下次消费时先到 redis 中查看是否存在该消息，存在则表示消息已经消费过，直接丢弃消息。
- 业务判断法：通常数据消费后都需要插入到数据库中，使用数据库的唯一性约束防止重复消费。每次消费直接尝试插入数据，如果提示唯一性字段重复，则直接丢失消息。一般都是通过这个业务判断的方法就可以简单高效地避免消息的重复处理了。



### 如何处理消息丢失的问题？

参考文献：https://xie.infoq.cn/article/b2548617f42117436afca7f4d



消息丢失的三个原因：

* 生产者：生产者推送消息到 MQ 中，由于网络抖动等原因消息没有推送到 MQ 中，或者消息推送到 MQ 中了但是 MQ 内部出错了，导致消息丢失。
* MQ：MQ 接收到消息后先把消息暂存在 OS Cache 中，消费者还没消费的时候 MQ 自己挂了，导致消息丢失。
* 消费者：消费者消费到了这条消息，但是还没来得及处理，消费者自己挂了，但是消费者已经告诉了 MQ 自己已经消费完了，导致消息丢失。



三大MQ如何处理消息丢失问题

**RabbitMQ**

生产者方面：

RabbitMQ 有两种方案可以避免消息丢失，一种是 RabbitMQ 的事务机制，另一种是 Confirm 模式。

* RabbitMQ事务机制，提供RabbitMQ客户端Channel接口，txSelect开启事务，txCommit提交事务，txRollback回滚事务。事务整个过程都是阻塞的，性能低，几乎没人用。
* Confirm模式，生产者发送消息后，不需要等待 MQ 的回应，MQ 接收成功后，则回调生产者的 ack 接口通知生产者消息投递成功了，否则 MQ 接收失败，回调 nack 接口通知生产者消息投递失败了，生产者可以重新对这条消息进行投递。

MQ方面：

通常 RabbitMQ 接收到消息之后写入 OS Cache 中，就会给生产者返回接收成功的回应，这时如果 RabbitMQ 挂了，消息也就丢失了。解决方法可以结合生产者的 Confirm 模式，配置 RabbitMQ 持久化到磁盘之后，才给生产者返回 ack 信号。

消费者方面：

RabbitMQ 在消费者端弄丢数据，是由于 RabbitMQ 的默认自动提交 ack 导致的。解决方法就是关闭 RabbitMQ 的自动响应 ack 即可。



**Kafka**

生产者方面：

不存在丢消息的问题，生产者基本不会弄丢消息，因为生产者发送消息会等待 Kafka 响应成功，如果响应失败，生产者会自动不断地重试。

MQ方面：

Kafka 通常会一台 leader + 两台 follower，当生产者消息刚写入 leader 成功，但是还没同步到 follower 时，leader 宕机了，此时会重新选举 leader，新的 leader 由于还未同步到这条数据，导致该条消息丢失。

解决办法是做一些配置，当有其他 follower 同步到了消息后才通知生产者消息接收成功了。配置如下：

- 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
- 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower。
- 在 producer 端设置 `acks=all` ：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。

按上面的配置配置后，就可以保证在 Kafka Broker 端就算 leader 故障了，进行新 leader 选举切换时，也不会丢失数据。

消费者方面：

Kafka 消费端弄丢数据原因跟 RabbitMQ 类似，Kafka 消费者会在接收到消息的时候，会自动提交一个 offset 给 Kafka，告诉 Kafka 消息已经处理了。处理方法也跟 RabbitMQ 类似，关闭 offset 的自动提交即可。



**RocketMQ**

RocketMQ 导致数据丢失的原因与前面的 RabbitMQ 和 Kafka 都很类似。生产者就是因为网络抖动等原因消息投递失败，或者 RocketMQ 自身的 Master 节点故障，主备切换故障之类的，消费者则有可能是异步处理导致还未处理成功就给 RocketMQ 提交了 offset 标识消息已处理了。RocketMQ还有一个补偿机制，生产者发送消息，MQ成功接收后，MQ会主动回调生产者一个预定接口来确认该消息是否应该rollback还是Ack。



**总结**

* 消费端导致的消息丢失都是由于数据还未处理成功确提前通知 MQ 消息已经处理成功了，禁止自动提交或异步操作即可，处理起来比较简单；
* 生产者和 MQ 自身导致的消息丢失则比较难处理，
  * RabbitMQ 使用了 Confirm 模式避免消息丢失；
  * Kafka 则配置所有 follower 同步成功才给生产者响应推送消息成功；
  * RocketMQ 则使用事务消息来保证消息的零丢失，针对不同的异常情况还提供了补偿机制进行处理。



### 如何保证消息的顺序性？

参考文献：https://xie.infoq.cn/article/c84491a814f99c7b9965732b1



**乱序背景**

在生产中经常会有一些类似报表系统这样的系统，需要做 MySQL 的 binlog 同步。比如订单系统要同步订单表的数据到大数据部门的 MySQL 库中用于报表统计分析，通常的做法是基于 Canal 这样的中间件去监听订单数据库的 binlog，然后把这些 binlog 发送到 MQ 中，再由消费者从 MQ 中获取 binlog 落地到大数据部门的 MySQL 中。﻿

在这个过程中，可能会有对某个订单的增删改操作，比如有三条 binlog 执行顺序是增加、修改、删除；消费者愣是换了顺序给执行成删除、修改、增加，这样能行吗？肯定是不行的



**RabbitMQ**

乱序原因：

对于 RabbitMQ 来说，导致顺序错乱的原因通常是消费者是集群部署，不同的消费者消费到了同一订单的不同的消息，如消费者A执行了增加，消费者B执行了修改，消费者C执行了删除，但是消费者C执行比消费者B快，消费者B又比消费者A快，就会导致消费 binlog 执行到数据库的时候顺序错乱，本该顺序是增加、修改、删除，变成了删除、修改、增加。

保序方法：

RabbitMQ 的问题是由于不同的消息都发送到了同一个 queue 中，多个消费者都消费同一个 queue 的消息。解决这个问题，我们可以给 RabbitMQ 创建多个 queue，每个消费者固定消费一个 queue 的消息，生产者发送消息的时候，同一个订单号的消息发送到同一个 queue 中，由于同一个 queue 的消息是一定会保证有序的，那么同一个订单号的消息就只会被一个消费者顺序消费，从而保证了消息的顺序性。



**Kafka**

乱序原因：

对于 Kafka 来说，一个 topic 下同一个 partition 中的消息肯定是有序的，生产者在写的时候可以指定一个 key，通过我们会用订单号作为 key，这个 key 对应的消息都会发送到同一个 partition 中，所以消费者消费到的消息也一定是有序的。

﻿那么为什么 Kafka 还会存在消息错乱的问题呢？问题就出在消费者身上。通常我们消费到同一个 key 的多条消息后，会使用多线程技术去并发处理来提高消息处理速度，否则一条消息的处理需要耗时几十 ms，1 秒也就只能处理几十条消息，吞吐量就太低了。而多线程并发处理的话，binlog 执行到数据库的时候就不一定还是原来的顺序了。

保序方法：

Kafka 从生产者到消费者消费消息这一整个过程其实都是可以保证有序的，导致最终乱序是由于消费者端需要使用多线程并发处理消息来提高吞吐量，比如消费者消费到了消息以后，开启 32 个线程处理消息，每个线程线程处理消息的快慢是不一致的，所以才会导致最终消息有可能不一致。

所以对于 Kafka 的消息顺序性保证，其实我们只需要保证同一个订单号的消息只被同一个线程处理的就可以了。由此我们可以在线程处理前增加个内存队列，每个线程只负责处理其中一个内存队列的消息，同一个订单号的消息发送到同一个内存队列中即可。



**RocketMQ**

乱序原因：

对于 RocketMQ 来说，每个 Topic 可以指定多个 MessageQueue，当我们写入消息的时候，会把消息均匀地分发到不同的 MessageQueue 中，比如同一个订单号的消息，增加 binlog 写入到 MessageQueue1 中，修改 binlog 写入到 MessageQueue2 中，删除 binlog 写入到 MessageQueue3 中。

﻿但是当消费者有多台机器的时候，会组成一个 Consumer Group，Consumer Group 中的每台机器都会负责消费一部分 MessageQueue 的消息，所以可能消费者A消费了 MessageQueue1 的消息执行增加操作，消费者B消费了 MessageQueue2 的消息执行修改操作，消费者C消费了 MessageQueue3 的消息执行删除操作，但是此时消费 binlog 执行到数据库的时候就不一定是消费者A先执行了，有可能消费者C先执行删除操作，因为几台消费者是并行执行，是不能够保证他们之间的执行顺序的。

保序方法：

RocketMQ 的消息乱序是由于同一个订单号的 binlog 进入了不同的 MessageQueue，进而导致一个订单的 binlog 被不同机器上的 Consumer 处理。﻿

要解决 RocketMQ 的乱序问题，我们只需要想办法让同一个订单的 binlog 进入到同一个 MessageQueue 中就可以了。因为同一个 MessageQueue 内的消息是一定有序的，一个 MessageQueue 中的消息只能交给一个 Consumer 来进行处理，所以 Consumer 消费的时候就一定会是有序的。



### 如何处理消费者故障导致的百万消息积压？

参考文献：https://xie.infoq.cn/article/a1f63436804102ca894a02f90



**为何导致消息积压？**

首先，可能是消费端出问题了，比如宕机等情况，或者消费端消费突然变得极慢，就会导致消息不断积压；也有可能是消费端依赖的服务器挂掉了，比如依赖的 NoSQL/MySQL 挂掉了，导致消费者自己没法正常运作了，导致消息的积压。



**如何解决消息积压问题？**

消息可丢的情况：

如果积压的这些消息是允许丢失的，那么很简单，马上修改消费者代码直接丢弃消息即可，这个速度会很快，所以积压消息处理起来也非常地迅速。



消息不可丢的情况：

最简单高效的办法就是临时部署足够多的消费者，一起来消费这些消息。当然，在此之前，需要先恢复系统的正常服务。

比如对于 RocketMQ 来说，原本一个 Topic 只有 4 个 MessageQueue，对应 4 个消费者。很明显如果消息积压了百万条，那么 4 个消息消费是不能够快速处理掉这一批积压消息的。我们可以修改 4 台原消费者代码，不直接处理消息，而是先把消息发送到一台新的RocketMQ 中，这台新的 RocketMQ 一个 Topic 有 20 个 MessageQueue，这时我们可以临时部署 20 个消费者一起消费这批数据，消息的消费速度提高了 5 倍，很快积压的百万消息都会被处理完毕。处理完积压的消息之后就可以下线临时部署的 20 台消费者了。



## Spring

### Spring Bean初始化 or 生命周期

参考文档： https://www.cnblogs.com/zrtqsk/p/3735273.html

参考文档：https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/framework/spring/Spring%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md#55-spring-%E4%B8%AD%E7%9A%84-bean-%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F



### Spring Boot 自动装配原理

参考文档：https://www.cnblogs.com/javaguide/p/springboot-auto-config.html



### SpringMVC 请求过程

参考文档：https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/framework/spring/Spring%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md#62-springmvc-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E4%BA%86%E8%A7%A3%E5%90%97



### Spring用到的设计模式

参考文档：https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/framework/spring/Spring%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md#7-spring-%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%94%A8%E5%88%B0%E4%BA%86%E5%93%AA%E4%BA%9B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F



### Spring事务

参考文档：https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/framework/spring/Spring%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.md#8-spring-%E4%BA%8B%E5%8A%A1







